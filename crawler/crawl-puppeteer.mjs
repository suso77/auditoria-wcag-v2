/**
 * ‚ôø CRAWLER AVANZADO CON PUPPETEER (con t√≠tulos de p√°gina)
 * -------------------------------------------------------
 * ‚úÖ Rastrea todas las URLs internas de un sitio hasta una profundidad definida.
 * ‚úÖ Ignora enlaces a archivos descargables (PDF, im√°genes, v√≠deos, docs, etc.).
 * ‚úÖ Detecta tipo de contenido real y guarda solo p√°ginas HTML.
 * ‚úÖ Extrae el <title> de cada p√°gina.
 * ‚úÖ Guarda resultados √∫nicos (URL + t√≠tulo) en scripts/urls.json.
 * -------------------------------------------------------
 */

import puppeteer from "puppeteer";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// üåê Configuraci√≥n principal
const SITE_URL = process.env.SITE_URL || "https://example.com";
const MAX_DEPTH = parseInt(process.env.MAX_DEPTH || "3", 10);
const TIMEOUT = parseInt(process.env.TIMEOUT || "20000", 10);

const visited = new Set();
const queue = [{ url: SITE_URL, depth: 0 }];
const results = [];

console.log(`üöÄ Iniciando rastreo JS en: ${SITE_URL}`);
console.log(`   Profundidad m√°xima: ${MAX_DEPTH}`);

// üîé Extensiones que deben excluirse del rastreo
const NON_HTML_EXTENSIONS = /\.(pdf|jpg|jpeg|png|gif|svg|webp|mp4|webm|avi|mov|ico|css|js|zip|rar|doc|docx|xls|xlsx)$/i;

// üßπ Normaliza URLs y elimina duplicados, anchors o querys irrelevantes
function normalizeUrl(url) {
  try {
    const u = new URL(url);
    u.hash = "";
    u.search = "";
    return u.href.replace(/\/$/, "");
  } catch {
    return null;
  }
}

// üï∑Ô∏è L√≥gica principal del rastreador
async function crawl() {
  const browser = await puppeteer.launch({
    headless: "new",
    args: ["--no-sandbox", "--disable-setuid-sandbox"],
  });

  const page = await browser.newPage();

  while (queue.length > 0) {
    const { url, depth } = queue.shift();
    if (depth > MAX_DEPTH) continue;

    const normalized = normalizeUrl(url);
    if (!normalized || visited.has(normalized)) continue;
    if (!normalized.startsWith(SITE_URL)) continue;
    if (NON_HTML_EXTENSIONS.test(normalized)) {
      console.log(`‚ö†Ô∏è  Ignorando archivo no HTML: ${normalized}`);
      continue;
    }

    visited.add(normalized);

    try {
      const response = await page.goto(normalized, {
        waitUntil: "networkidle2",
        timeout: TIMEOUT,
      });

      // ‚öôÔ∏è Validar tipo de contenido
      const contentType = response?.headers()["content-type"] || "";
      if (!contentType.includes("text/html")) {
        console.log(`‚ö†Ô∏è  Ignorando recurso no HTML (${contentType}): ${normalized}`);
        continue;
      }

      // Esperar breve para render completo del DOM
      await new Promise((r) => setTimeout(r, 800));

      // Extraer t√≠tulo de la p√°gina
      const title = await page.title();

      results.push({
        url: normalized,
        title: title || "(sin t√≠tulo)",
      });
      console.log(`üîó [${depth}] ${normalized} ‚Äî ‚Äú${title || "sin t√≠tulo"}‚Äù`);

      // Buscar nuevos enlaces internos
      const foundLinks = await page.$$eval("a[href]", (anchors) =>
        anchors.map((a) => a.href).filter(Boolean)
      );

      for (const link of foundLinks) {
        const next = normalizeUrl(link);
        if (
          next &&
          next.startsWith(SITE_URL) &&
          !visited.has(next) &&
          !queue.find((q) => q.url === next) &&
          !NON_HTML_EXTENSIONS.test(next)
        ) {
          queue.push({ url: next, depth: depth + 1 });
        }
      }
    } catch (err) {
      console.warn(`‚ö†Ô∏è  Error al acceder a ${normalized}: ${err.message}`);
    }
  }

  await browser.close();

  // üßæ Guardar resultados finales
  fs.mkdirSync(path.join(__dirname, "../scripts"), { recursive: true });
  fs.writeFileSync(
    path.join(__dirname, "../scripts/urls.json"),
    JSON.stringify(results, null, 2)
  );

  console.log("===============================================");
  console.log(`‚úÖ Rastreo completado correctamente`);
  console.log(`üåç Total de p√°ginas HTML guardadas: ${results.length}`);
  console.log(`üìÅ Archivo generado: scripts/urls.json`);
  console.log("===============================================");
}

crawl().catch((err) => {
  console.error("‚ùå Error en el crawler:", err);
  process.exit(1);
});

